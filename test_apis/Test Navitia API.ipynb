{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from navitia_client import Client\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.geometry.multipolygon import MultiPolygon\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import json\n",
    "\n",
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option('display.max_colwidth', 10000)\n",
    "\n",
    "# give the TravelMyWay API jey\n",
    "client = Client(user='8ad3db27-5eec-473d-9ff6-50d35fdf0da6')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_navitia_coverage():\n",
    "    \"\"\"\n",
    "    The navitia API is separated into different coverage region (one for california, one for PAris-IDF ...)\n",
    "    We call the API to get all those coverage and know which coverage region to call for a given scenario\n",
    "    \"\"\"\n",
    "    # call API for all coverages\n",
    "    response_cov = client.raw('coverage', multipage=False, page_limit=10, verbose=True)\n",
    "    # turn coverage into DF\n",
    "    df_cov = pd.DataFrame.from_dict(response_cov.json()['regions'])\n",
    "    \n",
    "    print(f'{df_cov.shape[0]} regions found, here is an example:\\n {df_cov.sample()}')\n",
    "    # clean the geographical shape\n",
    "    df_cov['polygon_clean'] = df_cov.apply(clean_polygon_for_coverage, axis=1)\n",
    "    return df_cov\n",
    "\n",
    "\n",
    "def clean_polygon_for_coverage(x):\n",
    "    \"\"\"\n",
    "    The API call for coverage returns multipolygons (a list of one or several polygon) for each region\n",
    "    but it is a string that we must convert to an actual Polygon object (in order to use function is point in polygon)\n",
    "    Most regions have only one polygon, so we decide to only consider the biggest polygon for each regions \n",
    "    \"\"\"\n",
    "    # split \"polygon\" as a string\n",
    "    if x['shape'] == '':\n",
    "        # Polygon is null\n",
    "        return None\n",
    "    \n",
    "    # split by '(' to see if there are several shape within polygon\n",
    "    split_meta = x['shape'].split('(')\n",
    "    # we want ton only keep the biggest Polygon, first we compute sizes for all \"polygon\"\n",
    "    sizes_pol = np.array([])\n",
    "    for i in split_meta:\n",
    "        sizes_pol = np.append(sizes_pol,len(sizes_pol))\n",
    "    # keep the biggest and act like there was only one from the beginning\n",
    "    split_pol = split_meta[np.argmax(sizes_pol)]\n",
    "    \n",
    "    # Let's split the polygon into a list of geoloc (lat, long)\n",
    "    split_pol = split_pol.split(',')\n",
    "    # clean the last point (the first and the last are the same cause the polygon has to be \"closed\")\n",
    "    split_pol[-1] = split_pol[0]\n",
    "    # recreate latitude and longitude list\n",
    "    lat = np.array([])\n",
    "    long =  np.array([])\n",
    "    for point in split_pol:\n",
    "        split_point = point.split(' ')\n",
    "        lat = np.append(lat,split_point[0])\n",
    "        long = np.append(long,split_point[1])\n",
    "    \n",
    "    # return the object Polygon\n",
    "    return Polygon(np.column_stack((long, lat)))\n",
    "\n",
    "\n",
    "def find_navita_coverage_for_points(point_from, point_to, df_cov):\n",
    "    \"\"\"\n",
    "    This function finds in which coverage regions are the 2 points. \n",
    "    If any point is not in any region, or the 2 points are in different regions we have an error\n",
    "    \"\"\"\n",
    "    # test if points are within polygon for each region\n",
    "    are_points_in_cov = df_cov[~pd.isna(df_cov.polygon_clean)].apply(lambda x: (x.polygon_clean.contains(point_from))&(x.polygon_clean.contains(point_to)), axis=1)\n",
    "    # find the good region \n",
    "    id_cov = df_cov[~pd.isna(df_cov.polygon_clean)][are_points_in_cov].id\n",
    "    if not id_cov.empty:\n",
    "        return id_cov.values[0]\n",
    "    else:\n",
    "        return 'no region found'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def section_json_summary(x):\n",
    "    \"\"\"\n",
    "    For each section we create a json with type of transportation + duration\n",
    "    \"\"\"\n",
    "    json_summary = {}\n",
    "    if not pd.isna(x['display_informations']):\n",
    "        json_summary[\"type\"] = x['display_informations']['physical_mode']\n",
    "    else :\n",
    "        json_summary[\"type\"] = x['type']\n",
    "    json_summary[\"duration\"] = x['duration']\n",
    "\n",
    "    return json_summary\n",
    "\n",
    "def get_section_details(x):\n",
    "    \"\"\" \n",
    "    For each journey we list all the section summary (type + duration)\n",
    "    \"\"\"\n",
    "    sections = pd.DataFrame.from_dict(x.sections)\n",
    "    sections['summary'] = sections.apply(section_json_summary, axis=1)\n",
    "    section_details = []\n",
    "    for value in sections['summary']: \n",
    "        section_details.append(value)\n",
    "    return section_details\n",
    "                   \n",
    "                   \n",
    "def compute_journey(point_from,point_to):\n",
    "    \"\"\"\n",
    "    Main function takes two points and compute detailed journeys between the 2. It does all the necessary steps\n",
    "    1 get the relevant coverage region\n",
    "    2 Call the navitia API\n",
    "    3 Compute details for each journey\n",
    "    \"\"\"\n",
    "    coverage_region = find_navita_coverage_for_points(point_from,point_to , df_cov)\n",
    "    if coverage_region == 'no region found':\n",
    "        return 'the points are not within the voverage of navitia API'\n",
    "    url = f'coverage/{coverage_region}/journeys?from={point_from.y};{point_from.x}&to={point_to.y};{point_to.x}'\n",
    "    response = client.raw(url, multipage=False, page_limit=10, verbose=True)\n",
    "    \n",
    "    df_journey = pd.DataFrame.from_dict(response.json()['journeys'])\n",
    "    print(f'{df_journey.shape[0]} journeys found')\n",
    "    df_journey['section_details'] = df_journey.apply(get_section_details, axis=1)\n",
    "    df_journey['price_total'] = df_journey.apply(lambda x: x.fare['total']['value'], axis = 1)\n",
    "    return df_journey[[]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import on url coverage \n",
      "45 regions found, here is an example:\n",
      "    dataset_created_at end_production_date  id     last_load_at    name                                              shape start_production_date   status\n",
      "36    20191002T084656            20191214  se  20191011T003103  Sweden  MULTIPOLYGON(((20.99723 68.90611,21.37536 68.7...              20191004  running\n"
     ]
    }
   ],
   "source": [
    "df_cov = get_navitia_coverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['arrival_date_time', 'calendars', 'co2_emission', 'departure_date_time', 'distances', 'duration', 'durations', 'fare', 'links', 'nb_transfers', 'requested_date_time', 'sections', 'status', 'tags', 'type', 'section_details', 'price_total'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journeys.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import on url coverage/fr-idf/journeys?from=2.370697;48.88471&to=2.470697;48.78471 \n",
      "2 journeys found\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date_time</th>\n",
       "      <th>calendars</th>\n",
       "      <th>co2_emission</th>\n",
       "      <th>departure_date_time</th>\n",
       "      <th>distances</th>\n",
       "      <th>duration</th>\n",
       "      <th>durations</th>\n",
       "      <th>fare</th>\n",
       "      <th>nb_transfers</th>\n",
       "      <th>requested_date_time</th>\n",
       "      <th>status</th>\n",
       "      <th>tags</th>\n",
       "      <th>type</th>\n",
       "      <th>section_details</th>\n",
       "      <th>price_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20191012T192931</td>\n",
       "      <td>[{'active_periods': [{'begin': '20191012', 'end': '20191020'}], 'week_pattern': {'monday': False, 'tuesday': False, 'friday': False, 'wednesday': False, 'thursday': False, 'sunday': False, 'saturday': True}}]</td>\n",
       "      <td>{'value': 491.5655, 'unit': 'gEC'}</td>\n",
       "      <td>20191012T182654</td>\n",
       "      <td>{'taxi': 0, 'car': 0, 'walking': 376, 'bike': 0, 'ridesharing': 0}</td>\n",
       "      <td>3757</td>\n",
       "      <td>{'taxi': 0, 'walking': 925, 'car': 0, 'ridesharing': 0, 'bike': 0, 'total': 3757}</td>\n",
       "      <td>{'found': True, 'total': {'currency': 'centime', 'value': '380.0'}, 'links': [{'internal': True, 'type': 'ticket', 'id': 'ticket_1_0', 'rel': 'tickets', 'templated': False}, {'internal': True, 'type': 'ticket', 'id': 'ticket_2_0', 'rel': 'tickets', 'templated': False}]}</td>\n",
       "      <td>2</td>\n",
       "      <td>20191012T181911</td>\n",
       "      <td>OTHER_EFFECT</td>\n",
       "      <td>[walking, ecologic]</td>\n",
       "      <td>best</td>\n",
       "      <td>[{'type': 'street_network', 'duration': 246}, {'type': 'Métro', 'duration': 420}, {'type': 'transfer', 'duration': 252}, {'type': 'waiting', 'duration': 228}, {'type': 'Métro', 'duration': 1260}, {'type': 'transfer', 'duration': 336}, {'type': 'waiting', 'duration': 264}, {'type': 'Bus', 'duration': 660}, {'type': 'street_network', 'duration': 91}]</td>\n",
       "      <td>380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20191012T193112</td>\n",
       "      <td>[{'active_periods': [{'begin': '20191012', 'end': '20191027'}], 'week_pattern': {'monday': False, 'tuesday': False, 'friday': False, 'wednesday': False, 'thursday': False, 'sunday': False, 'saturday': True}}]</td>\n",
       "      <td>{'value': 46.794, 'unit': 'gEC'}</td>\n",
       "      <td>20191012T182354</td>\n",
       "      <td>{'taxi': 0, 'car': 0, 'walking': 1632, 'bike': 0, 'ridesharing': 0}</td>\n",
       "      <td>4038</td>\n",
       "      <td>{'taxi': 0, 'walking': 1710, 'car': 0, 'ridesharing': 0, 'bike': 0, 'total': 4038}</td>\n",
       "      <td>{'found': True, 'total': {'currency': 'centime', 'value': '190.0'}, 'links': [{'internal': True, 'type': 'ticket', 'id': 'ticket_3_0', 'rel': 'tickets', 'templated': False}]}</td>\n",
       "      <td>1</td>\n",
       "      <td>20191012T181911</td>\n",
       "      <td>OTHER_EFFECT</td>\n",
       "      <td>[walking, ecologic]</td>\n",
       "      <td>comfort</td>\n",
       "      <td>[{'type': 'street_network', 'duration': 246}, {'type': 'Métro', 'duration': 420}, {'type': 'transfer', 'duration': 252}, {'type': 'waiting', 'duration': 168}, {'type': 'Métro', 'duration': 1740}, {'type': 'street_network', 'duration': 1212}]</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  arrival_date_time                                                                                                                                                                                                         calendars                        co2_emission departure_date_time                                                            distances  duration                                                                           durations                                                                                                                                                                                                                                                                            fare  nb_transfers requested_date_time        status                 tags     type                                                                                                                                                                                                                                                                                                                                                 section_details price_total\n",
       "0   20191012T192931  [{'active_periods': [{'begin': '20191012', 'end': '20191020'}], 'week_pattern': {'monday': False, 'tuesday': False, 'friday': False, 'wednesday': False, 'thursday': False, 'sunday': False, 'saturday': True}}]  {'value': 491.5655, 'unit': 'gEC'}     20191012T182654   {'taxi': 0, 'car': 0, 'walking': 376, 'bike': 0, 'ridesharing': 0}      3757   {'taxi': 0, 'walking': 925, 'car': 0, 'ridesharing': 0, 'bike': 0, 'total': 3757}  {'found': True, 'total': {'currency': 'centime', 'value': '380.0'}, 'links': [{'internal': True, 'type': 'ticket', 'id': 'ticket_1_0', 'rel': 'tickets', 'templated': False}, {'internal': True, 'type': 'ticket', 'id': 'ticket_2_0', 'rel': 'tickets', 'templated': False}]}             2     20191012T181911  OTHER_EFFECT  [walking, ecologic]     best  [{'type': 'street_network', 'duration': 246}, {'type': 'Métro', 'duration': 420}, {'type': 'transfer', 'duration': 252}, {'type': 'waiting', 'duration': 228}, {'type': 'Métro', 'duration': 1260}, {'type': 'transfer', 'duration': 336}, {'type': 'waiting', 'duration': 264}, {'type': 'Bus', 'duration': 660}, {'type': 'street_network', 'duration': 91}]       380.0\n",
       "1   20191012T193112  [{'active_periods': [{'begin': '20191012', 'end': '20191027'}], 'week_pattern': {'monday': False, 'tuesday': False, 'friday': False, 'wednesday': False, 'thursday': False, 'sunday': False, 'saturday': True}}]    {'value': 46.794, 'unit': 'gEC'}     20191012T182354  {'taxi': 0, 'car': 0, 'walking': 1632, 'bike': 0, 'ridesharing': 0}      4038  {'taxi': 0, 'walking': 1710, 'car': 0, 'ridesharing': 0, 'bike': 0, 'total': 4038}                                                                                                  {'found': True, 'total': {'currency': 'centime', 'value': '190.0'}, 'links': [{'internal': True, 'type': 'ticket', 'id': 'ticket_3_0', 'rel': 'tickets', 'templated': False}]}             1     20191012T181911  OTHER_EFFECT  [walking, ecologic]  comfort                                                                                                               [{'type': 'street_network', 'duration': 246}, {'type': 'Métro', 'duration': 420}, {'type': 'transfer', 'duration': 252}, {'type': 'waiting', 'duration': 168}, {'type': 'Métro', 'duration': 1740}, {'type': 'street_network', 'duration': 1212}]       190.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "To test the API, you can enter any point from and to and run the compute_journey function\n",
    "\"\"\"\n",
    "\n",
    "latitude_from = 48.88471\n",
    "longitude_from = 2.370697\n",
    "latitude_to = 48.78471\n",
    "longitude_to = 2.470697\n",
    "\n",
    "journeys = compute_journey(Point(latitude_from,longitude_from),Point(latitude_to,longitude_to))\n",
    "journeys[['arrival_date_time', 'calendars', 'co2_emission', 'departure_date_time', 'distances', 'duration',\n",
    "          'durations', 'fare', 'nb_transfers',\n",
    "          'requested_date_time', 'status', 'tags', 'type', 'section_details', 'price_total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'street_network', 'duration': 246},\n",
       " {'type': 'Métro', 'duration': 180},\n",
       " {'type': 'transfer', 'duration': 210},\n",
       " {'type': 'waiting', 'duration': 210},\n",
       " {'type': 'Train de banlieue / RER', 'duration': 900},\n",
       " {'type': 'transfer', 'duration': 336},\n",
       " {'type': 'waiting', 'duration': 264},\n",
       " {'type': 'Bus', 'duration': 360},\n",
       " {'type': 'waiting', 'duration': 480},\n",
       " {'type': 'Bus', 'duration': 600},\n",
       " {'type': 'street_network', 'duration': 91}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the details of a given journey\n",
    "journeys.section_details[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
